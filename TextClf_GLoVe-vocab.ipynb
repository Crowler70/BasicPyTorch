{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP in PyTorch\n",
    "# Binary Classification\n",
    "### Using GLoVe Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30524</th>\n",
       "      <td>30537</td>\n",
       "      <td>pos</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@Admance good morning mate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>pos</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>wide awake   NOT!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>8048</td>\n",
       "      <td>pos</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>#StarTrek in 41 minutes  haven't acquired #IPh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38391</th>\n",
       "      <td>38404</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@amethystgurl07 i know exactly what you feel. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49987</th>\n",
       "      <td>50000</td>\n",
       "      <td>pos</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@ashsimpsonwentz @petewentz happy anniversary!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID Sentiment SentimentSource  \\\n",
       "30524   30537       pos    Sentiment140   \n",
       "127       128       pos    Sentiment140   \n",
       "8045     8048       pos    Sentiment140   \n",
       "38391   38404       neg    Sentiment140   \n",
       "49987   50000       pos    Sentiment140   \n",
       "\n",
       "                                           SentimentText  \n",
       "30524                        @Admance good morning mate   \n",
       "127                                  wide awake   NOT!!!  \n",
       "8045   #StarTrek in 41 minutes  haven't acquired #IPh...  \n",
       "38391  @amethystgurl07 i know exactly what you feel. ...  \n",
       "49987  @ashsimpsonwentz @petewentz happy anniversary!...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('tweets.csv')\n",
    "tweets.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText Sentiment\n",
       "0                       is so sad for my APL frie...       neg\n",
       "1                     I missed the New Moon trail...       neg\n",
       "2                            omg its already 7:30 :O       pos\n",
       "3  .. Omgaga. Im sooo  im gunna CRy. I've been at...       neg\n",
       "4           i think mi bf is cheating on me!!!   ...       neg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[['SentimentText', 'Sentiment']]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    26921\n",
       "neg    23079\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# good split ~ low skewness\n",
    "tweets['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(tweets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('processed/train_tweets.csv', index=False)\n",
    "test.to_csv('processed/test_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to remove urls and @ mentions from twitter data and convert them to lower case\n",
    "# p1 keeps all the alphabets and numeric data\n",
    "# p2 removes http(s) word\n",
    "\n",
    "def clean_tweets(text):\n",
    "    p1 = re.compile(r'[^A-Za-z0-9]+')\n",
    "    text = re.sub(p1, ' ', str(text))\n",
    "    \n",
    "    p2 = re.compile(r'https? ')\n",
    "    text = re.sub(p2, ' ', text)\n",
    "    \n",
    "    text = re.sub('\\s\\s', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pre-processing is defined, it will not tokenize by default which is necessary\n",
    "TEXT = torchtext.data.Field(preprocessing=clean_tweets)\n",
    "LABEL = torchtext.data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SentimentText', <torchtext.data.field.Field at 0x23c50326988>),\n",
       " ('Sentiment', <torchtext.data.field.LabelField at 0x23c503269c8>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafields = [('SentimentText', TEXT), ('Sentiment', LABEL)]\n",
    "datafields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "trn, tst = TabularDataset.splits(path='processed', train='train_tweets.csv', test='test_tweets.csv',\n",
    "                                format='csv', skip_header=True, fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SentimentText': ['aceofsabres', 'apparently', 'the', 'iphone', 'still', 'likes', 'to', 'fuck', 'with', 'my', 'dyslexia', 'that', 'should', 'have', 'been', 'dragons'], 'Sentiment': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(trn[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building vocab using GLoVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = torchtext.vocab.GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trn has a len of 40K, we'll encode top 25K and use unk for rest\n",
    "TEXT.build_vocab(trn, max_size=25000, vectors=glove, unk_init=torch.Tensor.normal_)\n",
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 18472, 'pos': 21528})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.build_vocab(trn)\n",
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 24333), ('the', 12196), ('to', 11987), ('you', 10680), ('a', 9148), ('it', 8357), ('and', 6873), ('my', 6302), ('quot', 5593), ('is', 5161), ('that', 5016), ('for', 4966), ('s', 4964), ('in', 4907), ('t', 4769), ('me', 4554), ('of', 4407), ('on', 3935), ('have', 3679), ('so', 3626), ('but', 3513), ('m', 3458), ('be', 2913), ('not', 2860), ('just', 2761)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'i', 'the', 'to', 'you', 'a', 'it', 'and', 'my']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['london']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (trn, tst), device = device, batch_size=256, sort_key= lambda x: len(x.SentimentText)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 40)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iterator), len(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN architecture\n",
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 100 # since we have taken GLoVe of 100 D\n",
    "hidden_dim = 25\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiDirectRNN, self).__init__()\n",
    "            \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        # two layer RNN -> GRU cells stacked over each other\n",
    "        # dropout inside GRU config, is for each GRU layer\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2,\n",
    "                          bidirectional=True, dropout=0.3)\n",
    "        # dimensionality of the input is hidden * 2, because we get two hidden states in a bidirectional RNN\n",
    "        # one in the forward direction and another when we pass input in the reverse direction\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        embed_drop = self.dropout(embedded)\n",
    "        output, hidden = self.gru(embed_drop)\n",
    "        # access the last two hidden states from the forward and backward RNNs and concatenate them to get final hidden\n",
    "        hidden = torch.cat((hidden[-2,:], hidden[-1,:]), dim=1)\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden_1d = hidden.squeeze(0)\n",
    "        out = self.fc(hidden_1d)       \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiDirectRNN(\n",
       "  (embedding): Embedding(25002, 100)\n",
       "  (gru): GRU(100, 25, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiDirectRNN()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25002, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace the initial weights of the embedding layer with the pre-trained GLoVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we had added unk_init during build_vocab, unk and pad are already present as first two vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.618 | Train Acc: 65.38 %\n",
      "| Epoch: 02 | Train Loss: 0.500 | Train Acc: 75.85 %\n",
      "| Epoch: 03 | Train Loss: 0.435 | Train Acc: 80.09 %\n",
      "| Epoch: 04 | Train Loss: 0.376 | Train Acc: 83.42 %\n",
      "| Epoch: 05 | Train Loss: 0.335 | Train Acc: 85.65 %\n",
      "| Epoch: 06 | Train Loss: 0.305 | Train Acc: 87.06 %\n",
      "| Epoch: 07 | Train Loss: 0.280 | Train Acc: 88.41 %\n",
      "| Epoch: 08 | Train Loss: 0.262 | Train Acc: 89.08 %\n",
      "| Epoch: 09 | Train Loss: 0.247 | Train Acc: 89.91 %\n",
      "| Epoch: 10 | Train Loss: 0.232 | Train Acc: 90.54 %\n",
      "| Epoch: 11 | Train Loss: 0.221 | Train Acc: 91.07 %\n",
      "| Epoch: 12 | Train Loss: 0.209 | Train Acc: 91.39 %\n",
      "| Epoch: 13 | Train Loss: 0.199 | Train Acc: 91.91 %\n",
      "| Epoch: 14 | Train Loss: 0.188 | Train Acc: 92.54 %\n",
      "| Epoch: 15 | Train Loss: 0.181 | Train Acc: 92.82 %\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "epochs = 15\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for batch in train_iterator:\n",
    "        batch.SentimentText = batch.SentimentText.to(device)\n",
    "        batch.Sentiment = batch.Sentiment.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "        \n",
    "        rounded_pred = torch.round(torch.sigmoid(predictions))\n",
    "        \n",
    "        correct = (rounded_pred == batch.Sentiment).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_loss = epoch_loss/len(train_iterator)\n",
    "    train_acc = epoch_acc/len(train_iterator)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.692 | Test Acc: 73.42%\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "\n",
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_iterator:\n",
    "        batch.Sentiment = batch.Sentiment.to(device)\n",
    "        batch.SentimentText = batch.SentimentText.to(device)\n",
    "        \n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "        \n",
    "        rounded_pred = torch.round(torch.sigmoid(predictions))\n",
    "        \n",
    "        correct = (rounded_pred == batch.Sentiment).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    test_loss = epoch_loss/len(test_iterator)\n",
    "    test_acc = epoch_acc/len(test_iterator)\n",
    "    \n",
    "    print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual testing\n",
    "\n",
    "def manual_test(scentence):\n",
    "    tokens = clean_tweets(scentence)\n",
    "    embed = [TEXT.vocab.stoi[w] for w in tokens]\n",
    "    tensor = torch.LongTensor(embed)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    cuda_tensor = tensor.to(device)\n",
    "    pred = torch.sigmoid(model(cuda_tensor))\n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903268218040466"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_test('I hated the show #awful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024314794689416885"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_test('great movie... #nice #enjoyed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41913822293281555"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_test('okayish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}