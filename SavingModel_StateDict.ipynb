{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Out PyTorch Models\n",
    "## using state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      0    14.23        1.71  2.43               15.6        127   \n",
       "1      0    13.20        1.78  2.14               11.2        100   \n",
       "2      0    13.16        2.36  2.67               18.6        101   \n",
       "3      0    14.37        1.95  2.50               16.8        113   \n",
       "4      0    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('wine_data.csv')\n",
    "wine.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wine.drop('Class', axis=1)\n",
    "y = wine['Class']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "x_train = torch.tensor(X_train.values, device=device, dtype=torch.float)\n",
    "x_test = torch.tensor(X_test.values, device=device, dtype=torch.float)\n",
    "y_train = torch.from_numpy(Y_train.values).view(-1).long()\n",
    "y_test = torch.from_numpy(Y_test.values).view(-1).long()\n",
    "\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(x.columns)\n",
    "hidden_size = 100\n",
    "output_size = y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = torch.sigmoid(self.fc1(X))\n",
    "        X = torch.sigmoid(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        \n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 00 | Loss: 1.120957851409912 |\n",
      "| Epoch: 200 | Loss: 0.08118202537298203 |\n",
      "| Epoch: 400 | Loss: 0.07488358020782471 |\n",
      "| Epoch: 600 | Loss: 0.06929833441972733 |\n",
      "| Epoch: 800 | Loss: 0.06742268800735474 |\n",
      "| Epoch: 1000 | Loss: 0.06634220480918884 |\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%200 == 0:\n",
    "        print(f'| Epoch: {epoch:02} | Loss: {loss.item()} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.3174, -0.7476, -0.5077,  ...,  1.7408,  0.9695, -0.0112],\n",
       "                      [ 0.0984, -0.1170,  0.0505,  ..., -0.0309,  0.0694, -0.1982],\n",
       "                      [ 0.0289, -0.1681,  0.0736,  ...,  0.1236,  0.0858, -0.2163],\n",
       "                      ...,\n",
       "                      [-0.2032, -0.1376,  0.1451,  ..., -0.0629, -0.1519, -0.0685],\n",
       "                      [ 0.0701, -0.1985, -0.0361,  ..., -0.0561,  0.1514,  0.1154],\n",
       "                      [ 0.1549,  0.0719,  0.2771,  ...,  0.0184, -0.1196, -0.2086]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.4417,  0.2118, -0.1233,  0.0740, -0.1571,  0.0940,  0.2314, -0.0332,\n",
       "                       0.1918, -0.2418, -0.0343, -0.1892,  0.3358,  0.1843, -0.0535,  0.1941,\n",
       "                       0.1401, -0.0870, -0.1239, -0.1529, -0.0864, -0.0067,  0.1287, -0.1820,\n",
       "                      -0.2435, -0.0351,  0.1811, -0.2138, -0.0472,  0.0312, -0.1684,  0.2421,\n",
       "                       0.1856, -0.0831,  0.2681, -0.1177,  0.0956, -0.2170, -0.0209,  0.2735,\n",
       "                       0.2683, -0.0234,  0.1775,  0.1370, -0.0151, -0.2441,  0.2196, -0.1087,\n",
       "                      -0.1952,  0.2563, -0.1428, -0.1738, -0.0821, -0.0998, -0.2205,  0.0577,\n",
       "                      -0.0400, -0.0834, -0.2309,  0.2382, -0.2715,  0.2521,  0.2340,  0.0293,\n",
       "                      -0.1447,  0.1620,  0.2701,  0.1515, -0.2076,  0.1550,  0.1767,  0.0068,\n",
       "                       0.1150,  0.2092,  0.2243,  0.5544, -0.1460, -0.0868, -0.0912, -0.1904,\n",
       "                       0.0029, -0.0077, -0.2311, -0.1892, -0.1375, -0.0541, -0.6027, -0.0930,\n",
       "                       0.1750, -0.2488,  0.2206, -0.1489,  0.2452, -0.1463, -0.1994,  0.3954,\n",
       "                       0.2529, -0.1348,  0.0285,  0.1759], device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-8.7944e-01, -8.2684e-02, -2.2040e-02,  ...,  9.0662e-02,\n",
       "                       -4.2453e-03, -2.4221e-02],\n",
       "                      [-1.2740e+00, -1.1115e-01,  3.9559e-02,  ...,  9.8977e-02,\n",
       "                        1.2988e-01,  2.1236e-02],\n",
       "                      [-9.0039e-01, -1.7675e-01, -8.9955e-03,  ...,  7.7794e-02,\n",
       "                       -3.4068e-02, -1.7748e-02],\n",
       "                      ...,\n",
       "                      [ 1.0150e+00,  1.9153e-01,  8.9012e-02,  ..., -5.9800e-02,\n",
       "                       -3.0703e-03, -7.9230e-02],\n",
       "                      [-1.6409e+00, -9.3943e-02,  6.9631e-02,  ...,  5.2534e-02,\n",
       "                        6.5784e-02,  2.0570e-02],\n",
       "                      [-6.3764e-01, -7.1461e-03, -1.9924e-02,  ..., -6.8212e-03,\n",
       "                        3.4509e-02,  9.0420e-05]], device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0166, -0.0212,  0.0417, -0.0652,  0.0676, -0.0040,  0.0132,  0.1105,\n",
       "                       0.0566,  0.0344,  0.1014,  0.0891,  0.0577, -0.0082, -0.0451,  0.0711,\n",
       "                       0.0472,  0.0999,  0.0588, -0.0323, -0.0579, -0.0304, -0.0028,  0.0011,\n",
       "                       0.0660,  0.0415, -0.0361,  0.0167, -0.0603, -0.0482,  0.0319, -0.0055,\n",
       "                       0.0863, -0.0505, -0.0370,  0.0507,  0.0975,  0.0391,  0.1152, -0.0408,\n",
       "                      -0.0773, -0.0350,  0.0185,  0.0244,  0.0310, -0.0241,  0.0558,  0.0780,\n",
       "                       0.0105,  0.1267, -0.0769,  0.1019, -0.0530, -0.0460,  0.0256,  0.0712,\n",
       "                      -0.0769,  0.0260, -0.0023,  0.0118, -0.0587, -0.0493,  0.0298, -0.1255,\n",
       "                       0.0705, -0.0302, -0.0143, -0.0800,  0.0311,  0.0644, -0.1148,  0.1207,\n",
       "                       0.0287, -0.0761, -0.0116, -0.0070,  0.0038,  0.0475,  0.0541, -0.0015,\n",
       "                       0.0979,  0.0531, -0.0587,  0.0191, -0.0237,  0.0031, -0.1216, -0.0654,\n",
       "                      -0.0773, -0.0119, -0.1053, -0.0270, -0.0874,  0.0298, -0.0529,  0.0753,\n",
       "                       0.0029, -0.0278, -0.0253, -0.0096], device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.3551,  0.2776,  0.3597,  0.2606,  0.0106,  0.6123, -0.4131,  0.6229,\n",
       "                       -0.2669,  0.5151,  0.3851,  0.4930, -0.6104, -0.5917,  0.5286,  0.5873,\n",
       "                       -0.4273,  0.4094,  0.5848,  0.1719, -0.1931,  0.5934,  0.3951, -0.0333,\n",
       "                       -0.5120, -0.3988,  0.3112,  0.5360, -0.4242, -0.4895, -0.2608, -0.5283,\n",
       "                        0.4525,  0.5996,  0.5427,  0.5579,  0.3964,  0.3733,  0.5593,  0.4206,\n",
       "                        0.6793, -0.3179, -0.2322,  0.1614, -0.4094,  0.2694, -1.1951,  0.5272,\n",
       "                       -0.6832,  0.3358,  0.4627, -0.1981, -0.2336, -0.3398, -0.0952, -0.5562,\n",
       "                       -0.3978, -0.2396, -0.3937,  0.6594,  0.5866, -0.1539, -0.2424, -0.3480,\n",
       "                       -0.4719, -0.1769,  0.1558, -0.4587, -0.9527,  0.6155, -0.3201,  0.6505,\n",
       "                        0.7650, -0.0864, -0.3128, -0.4467,  0.4912,  0.0330,  0.5780,  0.3705,\n",
       "                       -0.8722,  0.3430, -0.5570,  0.7243,  0.5368, -0.2118, -0.2254,  0.3121,\n",
       "                       -0.2469, -0.5699,  0.7060, -0.9000,  0.5495, -0.3222, -0.6470,  0.5881,\n",
       "                       -1.2995, -0.2601,  0.1327, -0.4369],\n",
       "                      [-0.3334, -0.3736, -0.3573,  0.4751, -0.2432, -0.3499,  0.3272, -0.2497,\n",
       "                        0.2192, -0.2212, -0.2271, -0.3448, -0.4280, -0.1673, -0.1344, -0.2586,\n",
       "                        0.1191, -0.3318,  0.2380,  0.4406,  0.3284, -0.1848, -0.1887, -0.3838,\n",
       "                        0.1812,  0.3062, -0.3811, -0.1969,  0.3964,  0.0822,  0.1858,  0.3206,\n",
       "                       -0.2275, -0.2983, -0.2915, -0.0848, -0.3555, -0.2799, -0.3769, -0.3529,\n",
       "                        0.2653,  0.2422,  0.2534, -0.4511,  0.3071, -0.3509, -0.3851, -0.3439,\n",
       "                       -0.1977, -0.3243, -0.3438, -0.4237,  0.3393,  0.2044, -0.3572,  0.2429,\n",
       "                        0.2930,  0.3658,  0.1083,  0.0716, -0.3263,  0.2681,  0.2462,  0.3021,\n",
       "                        0.2506, -0.4939, -0.4361,  0.1950, -0.1991,  0.0573,  0.3846, -0.2562,\n",
       "                        0.1650, -0.0821,  0.2915,  0.2810,  0.2200,  0.3938, -0.3129,  0.5000,\n",
       "                       -0.2450, -0.3457, -0.2574, -0.1074, -0.3819, -0.5471,  0.3444,  0.4643,\n",
       "                        0.2940, -0.0626,  0.3059, -0.3618,  0.0848,  0.3079,  0.2555, -0.2619,\n",
       "                       -0.4562,  0.3478, -0.4362,  0.1625],\n",
       "                      [ 0.1113,  0.2399,  0.1022, -0.8213,  0.2304, -0.2205,  0.0122, -0.1290,\n",
       "                       -0.1192,  0.0476,  0.0199, -0.1271,  0.8145,  0.5671, -0.1599, -0.0725,\n",
       "                       -0.0522,  0.0191, -0.5723, -0.9170, -0.3579, -0.0772,  0.0116,  0.5355,\n",
       "                        0.0594, -0.0396,  0.1822, -0.0328,  0.0314,  0.1565, -0.1998,  0.1243,\n",
       "                        0.1188, -0.2636, -0.0922, -0.1847,  0.1268,  0.1576, -0.0309,  0.0709,\n",
       "                       -0.6242,  0.0355, -0.0956,  0.4641,  0.1010,  0.3111,  0.8596, -0.1061,\n",
       "                        0.5256,  0.2765, -0.1424,  0.4985, -0.3495, -0.0588,  0.5975,  0.2258,\n",
       "                        0.0137, -0.2655,  0.1793, -0.4598, -0.0526, -0.2555, -0.2363, -0.0916,\n",
       "                       -0.0020,  0.6212,  0.3284,  0.1216,  0.6520, -0.4655, -0.2254, -0.2271,\n",
       "                       -0.5602, -0.0051, -0.0156,  0.1188, -0.5521, -0.4982, -0.2363, -0.7664,\n",
       "                        0.7775,  0.2201,  0.5933, -0.4297, -0.0614,  1.0335, -0.0729, -0.6338,\n",
       "                       -0.0805,  0.3952, -0.6868,  0.5969, -0.2412, -0.0918,  0.2209,  0.0132,\n",
       "                        0.7411, -0.1692,  0.2920,  0.1905]], device='cuda:0')),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0627,  0.0522, -0.0133], device='cuda:0'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For prediction purposes ~ save and load only the model parameters\n",
    "- If you need to train the saved model/ checkpointing, need to save more than just the model state_dict. \n",
    "**Also need to save the state of the optimizer, epochs, score, etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {2341974338280: {'step': 1001,\n",
       "   'exp_avg': tensor([[-3.0795e-03, -2.2138e-04,  5.4252e-04,  ..., -3.5876e-04,\n",
       "             2.9269e-04,  1.0649e-02],\n",
       "           [ 1.9973e-29,  2.1143e-30,  3.3752e-30,  ...,  1.5037e-30,\n",
       "             3.7130e-30,  3.4874e-27],\n",
       "           [-2.5035e-32, -2.1109e-33, -4.1899e-33,  ..., -2.8523e-33,\n",
       "            -6.5197e-33, -5.8051e-31],\n",
       "           ...,\n",
       "           [-6.9455e-18, -7.5638e-19, -1.1791e-18,  ..., -7.6257e-19,\n",
       "            -1.8111e-18, -1.6229e-16],\n",
       "           [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "            -5.6052e-45, -5.6052e-45],\n",
       "           [-1.2676e-31, -1.1918e-32, -2.1327e-32,  ..., -1.4270e-32,\n",
       "            -3.3079e-32, -2.9428e-30]], device='cuda:0'),\n",
       "   'exp_avg_sq': tensor([[4.2967e-02, 1.8723e-03, 1.5117e-03,  ..., 2.2175e-04, 1.2669e-03,\n",
       "            1.0323e+02],\n",
       "           [7.3790e-16, 8.3132e-18, 2.1071e-17,  ..., 4.1849e-18, 2.5544e-17,\n",
       "            2.2336e-11],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00],\n",
       "           ...,\n",
       "           [1.7281e-34, 2.0512e-36, 4.9803e-36,  ..., 2.0826e-36, 1.1748e-35,\n",
       "            9.4365e-32],\n",
       "           [5.8210e-09, 2.1552e-10, 2.0641e-10,  ..., 3.2146e-11, 2.0754e-10,\n",
       "            7.5259e-06],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00]], device='cuda:0')},\n",
       "  2341974338520: {'step': 1001,\n",
       "   'exp_avg': tensor([-3.1922e-04,  1.1555e-30, -2.0838e-33, -5.6052e-45,  3.6665e-22,\n",
       "            2.3235e-15,  0.0000e+00, -2.9349e-36,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  6.5636e-34, -5.6052e-45,  0.0000e+00, -5.6052e-45,\n",
       "            0.0000e+00, -8.5296e-21,  0.0000e+00, -8.8831e-37,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  5.2073e-25, -5.2005e-27, -1.0095e-27,\n",
       "           -2.9081e-16,  0.0000e+00,  0.0000e+00, -5.6052e-45,  0.0000e+00,\n",
       "            1.1846e-39,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7245e-17,\n",
       "           -5.6052e-45, -1.4098e-14,  0.0000e+00, -1.9774e-24,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1354e-21,\n",
       "            0.0000e+00,  5.6171e-19,  0.0000e+00,  0.0000e+00, -5.6052e-45,\n",
       "           -5.6052e-45, -2.0639e-19, -1.7695e-17, -5.6052e-45, -7.7216e-20,\n",
       "            0.0000e+00,  0.0000e+00,  3.9682e-15,  0.0000e+00, -5.6052e-45,\n",
       "            5.8674e-21,  3.4688e-32,  2.8880e-35,  1.3312e-43,  4.9687e-31,\n",
       "            0.0000e+00, -2.9241e-20,  3.2135e-37,  8.3529e-25,  0.0000e+00,\n",
       "            1.4288e-41,  3.3390e-34,  9.6060e-15,  0.0000e+00,  0.0000e+00,\n",
       "            1.0182e-11,  0.0000e+00, -1.7269e-26, -1.2058e-24,  0.0000e+00,\n",
       "            0.0000e+00,  8.7932e-27,  0.0000e+00,  0.0000e+00, -2.7616e-34,\n",
       "           -9.8585e-35,  2.6974e-04, -1.6646e-19,  6.5019e-35,  0.0000e+00,\n",
       "            0.0000e+00,  2.3135e-21, -7.0193e-19,  0.0000e+00,  0.0000e+00,\n",
       "           -2.9100e-38, -1.4971e-23, -5.7566e-19, -5.6052e-45, -1.0535e-32],\n",
       "          device='cuda:0'),\n",
       "   'exp_avg_sq': tensor([2.6164e-04, 2.4782e-18, 0.0000e+00, 1.7009e-23, 0.0000e+00, 3.5582e-30,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.7354e-07, 0.0000e+00, 6.0838e-24, 0.0000e+00, 3.2664e-41, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 4.1374e-32, 0.0000e+00, 0.0000e+00, 2.3492e-11, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6203e-33, 6.5200e-26,\n",
       "           5.0786e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 8.7035e-42, 0.0000e+00, 5.7849e-37, 0.0000e+00,\n",
       "           0.0000e+00, 1.6718e-22, 6.7545e-23, 2.6053e-38, 7.2993e-20, 2.9627e-15,\n",
       "           3.2930e-39, 0.0000e+00, 0.0000e+00, 9.8809e-30, 0.0000e+00, 9.6361e-21,\n",
       "           1.8221e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           6.0884e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0835e-28, 0.0000e+00, 0.0000e+00, 1.1906e-06, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 2.8168e-05, 1.4451e-38, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 5.1119e-42, 2.7313e-37, 0.0000e+00, 0.0000e+00, 2.2482e-06,\n",
       "           0.0000e+00, 1.1871e-36, 3.7087e-11, 0.0000e+00], device='cuda:0')},\n",
       "  2342382505240: {'step': 1001,\n",
       "   'exp_avg': tensor([[ 7.0230e-06,  2.9990e-30,  1.0244e-32,  ...,  6.4836e-18,\n",
       "            -1.6330e-06,  1.4579e-31],\n",
       "           [ 8.9157e-06,  3.6086e-30,  9.5855e-33,  ...,  6.0670e-18,\n",
       "            -3.6161e-06,  1.3641e-31],\n",
       "           [ 6.6322e-06,  3.0756e-30,  1.0525e-32,  ...,  6.6614e-18,\n",
       "            -1.7886e-06,  1.4978e-31],\n",
       "           ...,\n",
       "           [-9.6347e-06, -3.1090e-30, -8.7529e-33,  ..., -5.5399e-18,\n",
       "             1.5879e-06, -1.2456e-31],\n",
       "           [ 1.0129e-05,  3.6292e-30,  7.8890e-33,  ...,  4.9937e-18,\n",
       "            -3.6982e-06,  1.1227e-31],\n",
       "           [-1.0540e-06, -1.2509e-30, -1.0468e-32,  ..., -6.6243e-18,\n",
       "            -6.2006e-07, -1.4898e-31]], device='cuda:0'),\n",
       "   'exp_avg_sq': tensor([[3.4869e-07, 1.6335e-17, 0.0000e+00,  ..., 2.4616e-35, 8.6772e-07,\n",
       "            0.0000e+00],\n",
       "           [5.0422e-07, 2.3695e-17, 0.0000e+00,  ..., 3.0187e-35, 1.3628e-06,\n",
       "            0.0000e+00],\n",
       "           [3.2694e-07, 1.7181e-17, 0.0000e+00,  ..., 2.3933e-35, 8.4556e-07,\n",
       "            0.0000e+00],\n",
       "           ...,\n",
       "           [2.7486e-07, 1.7583e-17, 0.0000e+00,  ..., 1.5496e-35, 7.8857e-07,\n",
       "            0.0000e+00],\n",
       "           [3.5688e-07, 2.3997e-17, 0.0000e+00,  ..., 1.1662e-35, 1.2269e-06,\n",
       "            0.0000e+00],\n",
       "           [1.6458e-07, 2.8051e-18, 0.0000e+00,  ..., 2.0563e-35, 3.5572e-07,\n",
       "            0.0000e+00]], device='cuda:0')},\n",
       "  2342453717736: {'step': 1001,\n",
       "   'exp_avg': tensor([-1.6330e-06, -3.6162e-06, -1.7886e-06, -4.3876e-06, -8.6760e-07,\n",
       "            2.5831e-06, -1.4281e-06,  2.2653e-06,  5.8182e-07,  5.5767e-07,\n",
       "            1.8440e-07,  1.2056e-06,  6.0975e-06,  5.8039e-06,  1.7317e-06,\n",
       "            1.9802e-06, -1.6031e-06, -2.4113e-07, -5.6393e-06, -4.0358e-06,\n",
       "            2.5312e-06,  1.4209e-06,  5.8423e-07,  4.2573e-07, -2.2154e-06,\n",
       "           -9.4987e-07, -2.6805e-06,  1.6507e-06, -1.0702e-06,  8.4779e-07,\n",
       "            1.2593e-06, -2.9607e-06, -6.1490e-07,  2.5621e-06,  1.8556e-06,\n",
       "            2.4464e-07, -1.8100e-06, -1.7131e-06,  1.1092e-06, -6.7885e-07,\n",
       "           -6.5310e-06, -1.6801e-06, -1.6769e-09, -3.8996e-06, -2.0246e-06,\n",
       "           -3.7729e-06,  8.8958e-06,  1.6025e-06,  5.8395e-06, -3.9071e-06,\n",
       "            9.0797e-07,  2.3318e-06,  2.6314e-06, -6.9308e-07,  1.9742e-06,\n",
       "           -2.0853e-06, -1.9737e-06,  2.2457e-06,  9.7037e-07, -5.7608e-06,\n",
       "            1.5893e-06,  1.6689e-06,  1.9610e-06,  3.5483e-08, -1.3984e-06,\n",
       "            2.0475e-06, -3.8539e-06, -2.2321e-06,  8.3446e-06, -5.4669e-06,\n",
       "            1.7980e-06,  2.5388e-06, -7.1974e-06, -4.6938e-08, -4.4060e-07,\n",
       "           -2.4438e-06, -5.0518e-06,  2.1433e-07,  2.4028e-06, -4.2005e-06,\n",
       "            7.9217e-06, -3.0744e-06,  5.7424e-06, -5.0644e-06,  1.0793e-06,\n",
       "            4.8376e-06,  8.3171e-07, -3.1776e-06,  8.7787e-08,  5.6701e-06,\n",
       "           -7.0222e-06,  5.5196e-06, -2.7124e-06, -1.3745e-07, -3.0450e-06,\n",
       "            4.9468e-07,  6.0826e-06,  1.5880e-06, -3.6982e-06, -6.2014e-07],\n",
       "          device='cuda:0'),\n",
       "   'exp_avg_sq': tensor([8.6949e-07, 1.3662e-06, 8.4719e-07, 3.0359e-06, 4.4664e-07, 9.2927e-07,\n",
       "           8.1338e-07, 7.1425e-07, 3.4907e-07, 5.7067e-07, 4.0551e-07, 6.5495e-07,\n",
       "           2.9689e-06, 1.2808e-06, 3.0871e-07, 7.9627e-07, 3.2578e-07, 7.2268e-07,\n",
       "           1.5829e-06, 3.6267e-06, 1.2487e-06, 3.4326e-07, 3.3539e-07, 1.9774e-06,\n",
       "           4.5092e-07, 8.5393e-07, 1.2654e-06, 5.2013e-07, 9.7446e-07, 3.5017e-07,\n",
       "           3.0176e-07, 9.8101e-07, 5.4625e-07, 6.9953e-07, 7.6077e-07, 3.4656e-07,\n",
       "           1.0552e-06, 8.8386e-07, 1.1734e-06, 1.1125e-06, 1.9600e-06, 4.2690e-07,\n",
       "           5.5102e-07, 2.1798e-06, 6.1933e-07, 1.3307e-06, 3.2147e-06, 8.8216e-07,\n",
       "           1.1735e-06, 9.0670e-07, 4.7059e-07, 1.7292e-06, 1.3821e-06, 3.4051e-07,\n",
       "           1.9404e-06, 7.4514e-07, 8.1590e-07, 1.4047e-06, 2.0390e-07, 8.1006e-07,\n",
       "           1.1022e-06, 8.4016e-07, 4.5474e-07, 8.2582e-07, 5.7596e-07, 2.9696e-06,\n",
       "           1.6360e-06, 4.6400e-07, 1.9269e-06, 7.4962e-07, 1.5324e-06, 6.6212e-07,\n",
       "           1.5526e-06, 1.0815e-10, 5.3095e-07, 6.4175e-07, 1.2074e-06, 2.0535e-06,\n",
       "           6.8576e-07, 3.7796e-06, 2.3854e-06, 1.1623e-06, 1.9283e-06, 8.8612e-07,\n",
       "           1.0410e-06, 5.9731e-06, 6.8665e-07, 2.7861e-06, 6.2218e-07, 8.0257e-07,\n",
       "           2.4791e-06, 1.3678e-06, 1.2907e-07, 8.8257e-07, 8.3125e-07, 5.8723e-07,\n",
       "           1.7214e-06, 7.8891e-07, 1.2269e-06, 3.5551e-07], device='cuda:0')},\n",
       "  2342453716136: {'step': 1001,\n",
       "   'exp_avg': tensor([[-1.3698e-05, -2.4936e-06, -1.5359e-05, -6.9944e-05,  1.7764e-05,\n",
       "            -2.6877e-05,  2.3893e-05, -2.6863e-05,  2.3807e-05, -2.3300e-05,\n",
       "            -2.0491e-05, -2.7208e-05,  8.9569e-05,  7.2821e-05, -2.7677e-05,\n",
       "            -2.2436e-05,  2.8414e-05, -1.9069e-05, -6.2151e-05, -6.3918e-05,\n",
       "             1.9929e-06, -3.6861e-05, -2.1798e-05,  4.5535e-05,  3.2875e-05,\n",
       "             1.9486e-05, -7.3846e-06, -2.3382e-05,  2.6059e-05,  2.2161e-05,\n",
       "             2.1515e-05,  2.4425e-05, -2.0207e-05, -2.9975e-05, -2.2519e-05,\n",
       "            -2.2973e-05, -1.3902e-05, -1.1953e-05, -2.0050e-05, -1.4082e-05,\n",
       "            -6.5552e-05,  2.2717e-05,  1.5013e-05,  1.6271e-05,  2.8045e-05,\n",
       "            -7.2737e-07,  1.1470e-04, -2.2743e-05,  7.7924e-05, -8.5560e-06,\n",
       "            -3.2163e-05,  6.7084e-05,  4.4084e-06,  3.0262e-05,  6.1016e-05,\n",
       "             2.4923e-05,  1.8035e-05,  6.3183e-06,  2.4581e-05, -4.4409e-05,\n",
       "            -2.0682e-05,  1.2155e-06,  1.8047e-05,  1.8118e-05,  3.1862e-05,\n",
       "             6.0475e-05,  8.0825e-06,  2.4283e-05,  7.6000e-05, -4.4348e-05,\n",
       "             1.0443e-05, -3.1143e-05, -4.9729e-05,  2.5959e-05,  2.4292e-05,\n",
       "             2.6446e-05, -7.7806e-05, -2.7115e-05, -3.0072e-05, -6.3700e-05,\n",
       "             9.1418e-05, -8.3613e-06,  6.2746e-05, -2.4112e-05, -2.1410e-05,\n",
       "             7.9608e-05,  1.6675e-05, -5.5637e-05,  1.7685e-05,  4.4832e-05,\n",
       "            -6.8582e-05,  1.0309e-04, -5.4284e-05,  1.4428e-05,  3.2918e-05,\n",
       "            -3.0150e-05,  1.0764e-04,  1.8838e-05,  3.8902e-06,  2.3445e-05],\n",
       "           [ 2.8842e-05,  3.4278e-05,  3.1069e-05, -6.4258e-05,  3.3169e-05,\n",
       "             6.3259e-06, -5.3987e-05,  6.9337e-06, -7.2669e-05,  1.9785e-05,\n",
       "             2.0365e-05,  1.7158e-05,  1.8713e-05,  2.1611e-05, -7.3444e-06,\n",
       "             8.2910e-06, -4.8969e-05,  2.2966e-05, -6.2294e-05, -6.5385e-05,\n",
       "            -7.9484e-05,  1.8021e-05,  1.7208e-05,  2.9801e-05, -4.5488e-05,\n",
       "            -5.4874e-05,  3.0731e-05,  9.4678e-06, -5.8685e-05, -5.6110e-06,\n",
       "            -8.2703e-05, -4.0737e-05,  2.7107e-05,  2.3548e-06,  9.5014e-06,\n",
       "            -2.4473e-05,  2.9036e-05,  2.8319e-05,  1.5569e-05,  2.1898e-05,\n",
       "            -6.1982e-05, -4.6760e-05, -6.0333e-05,  3.8662e-05, -4.9028e-05,\n",
       "             3.7754e-05,  1.1352e-05,  1.2424e-05,  2.0917e-05,  4.3566e-05,\n",
       "             2.1906e-05,  2.4872e-05, -7.7509e-05, -6.2083e-05,  2.6089e-05,\n",
       "            -2.3132e-05, -4.5738e-05, -7.1934e-05, -4.6887e-06, -6.1573e-05,\n",
       "             1.2123e-05, -7.2296e-05, -8.8494e-05, -6.1311e-05, -5.7461e-05,\n",
       "             2.5385e-05,  3.7552e-05, -3.0018e-05,  2.1493e-05, -6.1600e-05,\n",
       "            -6.8226e-05,  3.3565e-06, -6.2192e-05,  2.6690e-05, -6.1064e-05,\n",
       "            -4.2379e-05, -6.0720e-05, -7.1872e-05,  6.2670e-06, -6.3393e-05,\n",
       "             1.8189e-05,  3.4238e-05,  2.2575e-05, -4.5757e-05,  1.6263e-05,\n",
       "             2.1589e-05, -6.7699e-05, -6.5057e-05, -6.2581e-05,  2.1528e-05,\n",
       "            -6.1665e-05,  1.4952e-05, -6.2463e-05, -5.7909e-05, -3.5720e-05,\n",
       "             2.4936e-05,  1.3326e-05, -7.7252e-05,  4.2193e-05, -1.4962e-05],\n",
       "           [-1.5136e-05, -3.1777e-05, -1.5702e-05,  1.3421e-04, -5.0925e-05,\n",
       "             2.0558e-05,  3.0098e-05,  1.9936e-05,  4.8865e-05,  3.5216e-06,\n",
       "             1.3353e-07,  1.0056e-05, -1.0828e-04, -9.4428e-05,  3.5028e-05,\n",
       "             1.4152e-05,  2.0559e-05, -3.8894e-06,  1.2445e-04,  1.2931e-04,\n",
       "             7.7493e-05,  1.8848e-05,  4.5973e-06, -7.5330e-05,  1.2616e-05,\n",
       "             3.5391e-05, -2.3338e-05,  1.3921e-05,  3.2629e-05, -1.6547e-05,\n",
       "             6.1190e-05,  1.6316e-05, -6.8921e-06,  2.7627e-05,  1.3024e-05,\n",
       "             4.7453e-05, -1.5126e-05, -1.6359e-05,  4.4879e-06, -7.8086e-06,\n",
       "             1.2754e-04,  2.4047e-05,  4.5323e-05, -5.4926e-05,  2.0987e-05,\n",
       "            -3.7019e-05, -1.2605e-04,  1.0326e-05, -9.8838e-05, -3.5001e-05,\n",
       "             1.0264e-05, -9.1951e-05,  7.3103e-05,  3.1825e-05, -8.7099e-05,\n",
       "            -1.7875e-06,  2.7708e-05,  6.5619e-05, -1.9889e-05,  1.0599e-04,\n",
       "             8.5663e-06,  7.1083e-05,  7.0446e-05,  4.3196e-05,  2.5603e-05,\n",
       "            -8.5854e-05, -4.5627e-05,  5.7381e-06, -9.7489e-05,  1.0595e-04,\n",
       "             5.7786e-05,  2.7794e-05,  1.1193e-04, -5.2644e-05,  3.6776e-05,\n",
       "             1.5938e-05,  1.3853e-04,  9.8990e-05,  2.3812e-05,  1.2710e-04,\n",
       "            -1.0960e-04, -2.5869e-05, -8.5317e-05,  6.9876e-05,  5.1546e-06,\n",
       "            -1.0119e-04,  5.1026e-05,  1.2070e-04,  4.4898e-05, -6.6357e-05,\n",
       "             1.3025e-04, -1.1803e-04,  1.1675e-04,  4.3484e-05,  2.8054e-06,\n",
       "             5.2212e-06, -1.2097e-04,  5.8415e-05, -4.6075e-05, -8.4790e-06]],\n",
       "          device='cuda:0'),\n",
       "   'exp_avg_sq': tensor([[1.2156e-05, 1.3784e-05, 1.1258e-05, 9.4979e-06, 1.0908e-05, 9.9681e-06,\n",
       "            1.3821e-05, 9.8175e-06, 1.6643e-05, 1.0076e-05, 1.1472e-05, 1.0434e-05,\n",
       "            5.6093e-06, 1.0443e-05, 1.0752e-05, 1.0171e-05, 1.4815e-05, 1.0176e-05,\n",
       "            1.4142e-05, 9.6171e-06, 1.2783e-05, 8.5533e-06, 1.1199e-05, 1.2186e-05,\n",
       "            1.4603e-05, 1.6104e-05, 1.1863e-05, 9.2980e-06, 1.4927e-05, 1.4614e-05,\n",
       "            1.5165e-05, 1.4549e-05, 1.0210e-05, 1.0657e-05, 9.4822e-06, 1.2145e-05,\n",
       "            1.1748e-05, 1.3315e-05, 9.4437e-06, 1.2776e-05, 1.2917e-05, 1.3984e-05,\n",
       "            1.6098e-05, 9.9824e-06, 1.5979e-05, 1.1716e-05, 3.8586e-06, 1.0925e-05,\n",
       "            9.0511e-06, 1.0970e-05, 9.9105e-06, 1.2646e-05, 1.2942e-05, 1.3441e-05,\n",
       "            1.1849e-05, 1.3997e-05, 1.4422e-05, 1.4228e-05, 1.4063e-05, 1.0443e-05,\n",
       "            1.2845e-05, 1.5944e-05, 1.3081e-05, 1.8009e-05, 1.5023e-05, 1.1860e-05,\n",
       "            1.1177e-05, 1.3622e-05, 5.3947e-06, 1.0726e-05, 1.3464e-05, 9.4878e-06,\n",
       "            1.1410e-05, 1.3224e-07, 1.7774e-05, 1.5311e-05, 2.1474e-05, 1.3023e-05,\n",
       "            1.0386e-05, 1.1548e-05, 5.4075e-06, 1.2205e-05, 1.1646e-05, 1.0242e-05,\n",
       "            9.7664e-06, 1.0341e-05, 1.6754e-05, 1.1590e-05, 1.4253e-05, 1.4346e-05,\n",
       "            1.2535e-05, 3.8388e-06, 9.5363e-06, 1.6511e-05, 1.4674e-05, 9.1357e-06,\n",
       "            1.5964e-06, 1.3511e-05, 9.2217e-06, 1.3776e-05],\n",
       "           [2.4668e-05, 2.9333e-05, 2.1858e-05, 3.4025e-05, 2.8508e-05, 1.8496e-05,\n",
       "            4.7708e-05, 1.9498e-05, 5.9522e-05, 2.0221e-05, 2.7587e-05, 2.1898e-05,\n",
       "            1.9036e-05, 3.1466e-05, 2.6838e-05, 2.0272e-05, 5.0125e-05, 2.2036e-05,\n",
       "            4.4078e-05, 3.2971e-05, 4.2841e-05, 1.7811e-05, 2.8584e-05, 2.8173e-05,\n",
       "            5.1483e-05, 5.2320e-05, 2.4926e-05, 2.1212e-05, 4.9678e-05, 4.1372e-05,\n",
       "            5.8478e-05, 4.3778e-05, 2.0550e-05, 2.0956e-05, 1.9631e-05, 3.2096e-05,\n",
       "            2.3133e-05, 2.8386e-05, 1.8391e-05, 2.5178e-05, 4.1286e-05, 4.5803e-05,\n",
       "            5.2937e-05, 2.1831e-05, 5.0987e-05, 2.4479e-05, 1.8864e-05, 2.1998e-05,\n",
       "            2.9682e-05, 2.1758e-05, 2.0253e-05, 3.1518e-05, 4.2896e-05, 4.8301e-05,\n",
       "            2.8697e-05, 4.0657e-05, 4.6802e-05, 4.4132e-05, 4.1442e-05, 3.2904e-05,\n",
       "            2.2529e-05, 5.4736e-05, 5.2451e-05, 5.6293e-05, 5.2830e-05, 2.7414e-05,\n",
       "            2.3858e-05, 4.3930e-05, 2.3222e-05, 3.3960e-05, 4.3115e-05, 1.9990e-05,\n",
       "            3.4951e-05, 2.7530e-06, 5.9072e-05, 4.8350e-05, 5.6511e-05, 4.3266e-05,\n",
       "            2.0030e-05, 3.9254e-05, 2.2117e-05, 2.4448e-05, 3.0726e-05, 2.5483e-05,\n",
       "            1.9186e-05, 2.3572e-05, 5.5680e-05, 4.0409e-05, 4.9173e-05, 3.9232e-05,\n",
       "            4.0728e-05, 1.8088e-05, 3.2841e-05, 5.2173e-05, 4.3888e-05, 1.8208e-05,\n",
       "            8.8420e-06, 4.8175e-05, 1.9674e-05, 3.8971e-05],\n",
       "           [2.6923e-05, 3.3002e-05, 2.3484e-05, 2.3362e-05, 3.4560e-05, 1.8289e-05,\n",
       "            4.0069e-05, 1.9681e-05, 5.3661e-05, 2.1190e-05, 2.9949e-05, 2.1500e-05,\n",
       "            2.2718e-05, 3.5517e-05, 2.8384e-05, 2.1225e-05, 4.3476e-05, 2.1914e-05,\n",
       "            4.2032e-05, 2.1967e-05, 3.4336e-05, 1.7077e-05, 3.0798e-05, 3.2887e-05,\n",
       "            4.4255e-05, 4.6205e-05, 2.6617e-05, 2.1464e-05, 4.1606e-05, 3.4806e-05,\n",
       "            4.8465e-05, 3.5516e-05, 2.2008e-05, 2.0955e-05, 1.9921e-05, 3.5574e-05,\n",
       "            2.4663e-05, 3.2382e-05, 1.7706e-05, 2.7251e-05, 3.8785e-05, 3.8694e-05,\n",
       "            5.0323e-05, 2.4113e-05, 4.3683e-05, 2.7018e-05, 2.4912e-05, 2.2098e-05,\n",
       "            3.3975e-05, 2.3648e-05, 2.0161e-05, 3.7903e-05, 3.4429e-05, 3.9188e-05,\n",
       "            3.4152e-05, 3.2920e-05, 4.0395e-05, 3.8474e-05, 3.4761e-05, 3.2051e-05,\n",
       "            2.3655e-05, 5.5863e-05, 4.1252e-05, 5.2627e-05, 4.4279e-05, 3.1808e-05,\n",
       "            2.6100e-05, 3.6390e-05, 2.7061e-05, 3.2833e-05, 3.6714e-05, 1.9070e-05,\n",
       "            3.2816e-05, 2.9452e-06, 5.5208e-05, 4.1521e-05, 5.5669e-05, 3.8082e-05,\n",
       "            2.0039e-05, 3.1324e-05, 2.8129e-05, 2.6830e-05, 3.3858e-05, 2.4113e-05,\n",
       "            1.8450e-05, 2.6365e-05, 5.1639e-05, 3.3752e-05, 4.4200e-05, 3.8653e-05,\n",
       "            3.7510e-05, 2.2899e-05, 3.4490e-05, 4.7899e-05, 3.5061e-05, 1.7325e-05,\n",
       "            1.2279e-05, 3.8388e-05, 2.1408e-05, 3.0697e-05]], device='cuda:0')},\n",
       "  2341974352824: {'step': 1001,\n",
       "   'exp_avg': tensor([ 1.2001e-06, -3.9775e-05,  3.8586e-05], device='cuda:0'),\n",
       "   'exp_avg_sq': tensor([4.7480e-05, 1.4214e-04, 1.3986e-04], device='cuda:0')}},\n",
       " 'param_groups': [{'lr': 0.01,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'params': [2341974338280,\n",
       "    2341974338520,\n",
       "    2342382505240,\n",
       "    2342453717736,\n",
       "    2342453716136,\n",
       "    2341974352824]}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/clf_st_dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Net()\n",
    "new_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(torch.load('models/clf_st_dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 0, 0, 2, 2, 1, 0, 0, 1, 1, 1, 2, 2, 2, 1, 0, 2, 1, 0, 2, 0, 1, 2,\n",
       "        1, 1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 2, 2, 0, 2, 1, 1, 1, 1],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = new_model(x_test)\n",
    "\n",
    "_, pred = torch.max(prediction, 1)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = y_test.cpu().detach().numpy()\n",
    "predicted = pred.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956\n",
      "Precision: 0.957\n",
      "Recall: 0.956\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy_score(actual, predicted):.3f}')\n",
    "print(f'Precision: {precision_score(actual, predicted, average=\"weighted\"):.3f}')\n",
    "print(f'Recall: {recall_score(actual, predicted, average=\"weighted\"):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
