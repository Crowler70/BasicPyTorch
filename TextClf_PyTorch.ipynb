{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP in PyTorch\n",
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>ham</td>\n",
       "      <td>Shuhui has bought ron's present it's a swatch ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>ham</td>\n",
       "      <td>Jay says that you're a double-faggot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol I have to take it. member how I said my au...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wot u up 2? Thout u were gonna call me!! Txt b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok. I only ask abt e movie. U wan ktv oso?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v1                                                 v2 Unnamed: 2  \\\n",
       "2889  ham  Shuhui has bought ron's present it's a swatch ...        NaN   \n",
       "529   ham               Jay says that you're a double-faggot        NaN   \n",
       "2590  ham  Lol I have to take it. member how I said my au...        NaN   \n",
       "4033  ham  Wot u up 2? Thout u were gonna call me!! Txt b...        NaN   \n",
       "2519  ham         Ok. I only ask abt e movie. U wan ktv oso?        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "2889        NaN        NaN  \n",
       "529         NaN        NaN  \n",
       "2590        NaN        NaN  \n",
       "4033        NaN        NaN  \n",
       "2519        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                      Ok lar... Joking wif u oni...   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns={'v1' : 'label', 'v2' : 'text'})\n",
    "data = data[['text', 'label']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "train.reset_index(drop=True)\n",
    "test.reset_index(drop=True)\n",
    "\n",
    "train.to_csv('processed/train.csv', index=False)\n",
    "test.to_csv('processed/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext Field parameter specify how data should be preprocessed\n",
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Field - by default tokenizes the words based on space\n",
    "TEXT = Field()\n",
    "LABEL = torchtext.data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text', <torchtext.data.field.Field at 0x21a02154208>),\n",
       " ('label', <torchtext.data.field.LabelField at 0x21a02145fc8>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafields = [('text', TEXT), ('label', LABEL)]\n",
    "datafields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field objects know how to process the raw data \n",
    "# we need to specify what raw data they should work on which is done using TabularDataset\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "# splits data into train/test as torchtext.datasets objects & process the data using the Fields defined\n",
    "trn, tst = TabularDataset.splits(path='processed', train='train.csv', test='test.csv',\n",
    "                                 format='csv', skip_header=True, fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x21a02155fc8>,\n",
       " <torchtext.data.example.Example at 0x21a02162048>,\n",
       " <torchtext.data.example.Example at 0x21a02162088>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# every record is now represented using an example object\n",
    "trn[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x21a02776248>,\n",
       " <torchtext.data.example.Example at 0x21a027762c8>,\n",
       " <torchtext.data.example.Example at 0x21a02776688>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'label'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each object is represented by text and label keys\n",
    "trn[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'PASS', 'to', '69669', 'to', 'collect', 'your', 'polyphonic', 'ringtones.', 'Normal', 'gprs', 'charges', 'apply', 'only.', 'Enjoy', 'your', 'tones']\n"
     ]
    }
   ],
   "source": [
    "print(trn[5].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Text', 'PASS', 'to', '69669', 'to', 'collect', 'your', 'polyphonic', 'ringtones.', 'Normal', 'gprs', 'charges', 'apply', 'only.', 'Enjoy', 'your', 'tones'], 'label': 'spam'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(trn.examples[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the TEXT field to convert words into integers, it needs to be told what the entire vocabulary is\n",
    "# To do this, build_vocab by passing in the dataset to build the vocabulary on\n",
    "TEXT.build_vocab(trn, max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)\n",
    "# extra 2 are for unk (words that are outside of top 10K will be considered to be unknown) \n",
    "# and padding (to make words of the same length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.build_vocab(tst)\n",
    "len(LABEL.vocab)\n",
    "# contains just spam and ham labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 1744), ('you', 1311), ('I', 1177), ('a', 1060), ('the', 957), ('and', 682), ('in', 638), ('is', 611), ('i', 591), ('u', 549), ('for', 522), ('my', 507), ('of', 463), ('me', 455), ('your', 434), ('on', 395), ('have', 394), ('that', 347), ('2', 321), ('are', 315), ('it', 315), ('call', 307), ('or', 301), ('at', 295), ('be', 280)]\n"
     ]
    }
   ],
   "source": [
    "# most common 10 words\n",
    "print(TEXT.vocab.freqs.most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'to', 'you', 'I', 'a', 'the', 'and', 'in', 'is']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what words correspond to the numeric integers, you can use itos\n",
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numeric representation of individual strings can be known using stoi\n",
    "TEXT.vocab.stoi['you']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up an iterator that will iterate over our text in batches\n",
    "\n",
    "Bucket iterator returns a batch of examples where every example is of a similar length\n",
    "For each batch of text data that is feed into an RNN, the RNN memory cell has to be unrolled to the length of the sentences in that batch.\n",
    "All of the sentences in the batch have to have the same length, which means they may need to be padded.\n",
    "The bucket iterator tries to return examples of a similar length in each batch, thus minimizing the padding per example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "\n",
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (trn, tst), # pass in the datasets we want the iterator to draw data from\n",
    "    device = device,\n",
    "    batch_size = 128,\n",
    "    sort_key = lambda x: len(x.text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Embedding class in PyTorch converts the one-hot encoded sentences into a dense format using embeddings to represent individual words, rather than one-hot feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        # input to RNN cell is the current word's embeddings and the previous hidden state\n",
    "        # instead of basic RNN cell, can use GRU cell without anyother code changes\n",
    "        # self.rnn = nn.GRU(embedding_dim, hidden_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        # text: [scentence_length, batch_size]\n",
    "        # every input scentence is a list of indices of the one-hot encoded words\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        # words will now be represented using its embeddings\n",
    "        # embedded: [scentence_length, batch_size, embedding_dim]\n",
    "        embed_drop = self.dropout(embedded)\n",
    "        \n",
    "        # RNN cells produces, output as well as hidden state for next iteration\n",
    "        output, hidden = self.rnn(embed_drop)\n",
    "        # output: [scentence_length, batch_size, hidden_dim]\n",
    "        # hidden: [1, batch_size, hidden_dim]\n",
    "        \n",
    "        hidden_1d = hidden.squeeze(0)\n",
    "        \n",
    "        out = self.fc(hidden_1d)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        # input to LSTM cell is the current word's embeddings and the previous hidden state\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        # text: [scentence_length, batch_size]\n",
    "        # every input scentence is a list of indices of the one-hot encoded words\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        # words will now be represented using its embeddings\n",
    "        # embedded: [scentence_length, batch_size, embedding_dim]\n",
    "        embed_out = self.dropout(embedded)\n",
    "        # LSTM cells produces, output, last hidden state and last cell state of LSTM cell\n",
    "        output, (hidden, _) = self.lstm(embed_out)\n",
    "        # output: [scentence_length, batch_size, hidden_dim]\n",
    "        # hidden: [1, batch_size, hidden_dim]\n",
    "        \n",
    "        hidden_1d = hidden.squeeze(0)\n",
    "        \n",
    "        out = self.fc(hidden_1d)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(10002, 100)\n",
       "  (lstm): LSTM(100, 256)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)\n",
    "model = LSTM(input_dim, embedding_dim, hidden_dim, output_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross-entropy with logits = cross-entropy for binary classification+sigmoid function to get predictions b/w 0 and 1\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, iterator):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        batch.text = batch.text.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # model outputs data in form [batch_size, 1]\n",
    "        # needs to be converted to [batch_size]\n",
    "        predictions =  model(batch.text).squeeze(1)\n",
    "\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        # sigmoid the predictions to get val b.w 0 and 1\n",
    "        # round it off, to make it fall under a single label\n",
    "        rounded_pred = torch.round(torch.sigmoid(predictions))\n",
    "\n",
    "        correct = (rounded_pred == batch.label).float()\n",
    "\n",
    "        acc = correct.sum() / len(correct)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.470 | Train Acc: 86.35 %\n",
      "| Epoch: 02 | Train Loss: 0.398 | Train Acc: 86.37 %\n",
      "| Epoch: 03 | Train Loss: 0.398 | Train Acc: 86.39 %\n",
      "| Epoch: 04 | Train Loss: 0.398 | Train Acc: 86.45 %\n",
      "| Epoch: 05 | Train Loss: 0.398 | Train Acc: 86.48 %\n",
      "| Epoch: 06 | Train Loss: 0.398 | Train Acc: 86.48 %\n",
      "| Epoch: 07 | Train Loss: 0.397 | Train Acc: 86.47 %\n",
      "| Epoch: 08 | Train Loss: 0.398 | Train Acc: 86.54 %\n",
      "| Epoch: 09 | Train Loss: 0.398 | Train Acc: 86.59 %\n",
      "| Epoch: 10 | Train Loss: 0.398 | Train Acc: 86.54 %\n",
      "| Epoch: 11 | Train Loss: 0.399 | Train Acc: 86.61 %\n",
      "| Epoch: 12 | Train Loss: 0.397 | Train Acc: 86.60 %\n",
      "| Epoch: 13 | Train Loss: 0.398 | Train Acc: 86.59 %\n",
      "| Epoch: 14 | Train Loss: 0.398 | Train Acc: 86.61 %\n",
      "| Epoch: 15 | Train Loss: 0.397 | Train Acc: 86.58 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_model(model, train_iterator)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = 0\n",
    "epoch_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.469 | Test Acc: 86.56 %\n"
     ]
    }
   ],
   "source": [
    "# to check the model against test data\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch in test_iterator:\n",
    "        batch.text = batch.text.to(device)\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        rounded_pred = torch.round(torch.sigmoid(predictions))\n",
    "        \n",
    "        correct = (rounded_pred == batch.label).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    test_loss = epoch_loss/len(test_iterator)\n",
    "    test_acc = epoch_acc/len(test_iterator)\n",
    "        \n",
    "    print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
